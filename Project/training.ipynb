{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29698cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.py\n",
    "\n",
    "\n",
    "# Importing Libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d45ce3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and initializing the CNN model\n",
    "\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eb99c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding first convolution layer and pooling\n",
    "classifier.add(Convolution2D(32, (3, 3), input_shape=(64, 64, 1), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Adding second convolution layer and pooling\n",
    "classifier.add(Convolution2D(32, (3, 3), activation='relu'))\n",
    "# The input shape is set to the pooled feature maps from the previous convolution layer\n",
    "# Flattening the layers\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19374bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a fully connected layer\n",
    "classifier.add(Dense(units=128, activation='relu'))\n",
    "classifier.add(Dense(units=4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67b0417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "#categorical_crossentropy for multi-class classification\n",
    "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d9f49cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4162 images belonging to 4 classes.\n",
      "Found 441 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Preparing the train/test data and training the model\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('data/train',\n",
    "                                                 target_size=(64, 64),\n",
    "                                                 batch_size=32,\n",
    "                                                 color_mode='grayscale',\n",
    "                                                 class_mode='categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('data/test',\n",
    "                                            target_size=(64, 64),\n",
    "                                            batch_size=32,\n",
    "                                            color_mode='grayscale',\n",
    "                                            class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "377962f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "31/31 [==============================] - 35s 820ms/step - loss: 1.1860 - accuracy: 0.6123 - val_loss: 0.6599 - val_accuracy: 0.8125\n",
      "Epoch 2/10\n",
      "31/31 [==============================] - 20s 613ms/step - loss: 0.2634 - accuracy: 0.9141 - val_loss: 0.6434 - val_accuracy: 0.7891\n",
      "Epoch 3/10\n",
      "31/31 [==============================] - 15s 463ms/step - loss: 0.0895 - accuracy: 0.9678 - val_loss: 0.1436 - val_accuracy: 0.9531\n",
      "Epoch 4/10\n",
      "31/31 [==============================] - 11s 351ms/step - loss: 0.1178 - accuracy: 0.9678 - val_loss: 0.5859 - val_accuracy: 0.8438\n",
      "Epoch 5/10\n",
      "31/31 [==============================] - 10s 298ms/step - loss: 0.0904 - accuracy: 0.9727 - val_loss: 0.6856 - val_accuracy: 0.8359\n",
      "Epoch 6/10\n",
      "31/31 [==============================] - 9s 273ms/step - loss: 0.0606 - accuracy: 0.9854 - val_loss: 0.6194 - val_accuracy: 0.7812\n",
      "Epoch 7/10\n",
      "31/31 [==============================] - 7s 233ms/step - loss: 0.0466 - accuracy: 0.9863 - val_loss: 0.4733 - val_accuracy: 0.9062\n",
      "Epoch 8/10\n",
      "31/31 [==============================] - 8s 247ms/step - loss: 0.0194 - accuracy: 0.9960 - val_loss: 0.4249 - val_accuracy: 0.9609\n",
      "Epoch 9/10\n",
      "31/31 [==============================] - 7s 228ms/step - loss: 0.0444 - accuracy: 0.9849 - val_loss: 3.2934 - val_accuracy: 0.6484\n",
      "Epoch 10/10\n",
      "31/31 [==============================] - 8s 261ms/step - loss: 0.0575 - accuracy: 0.9824 - val_loss: 0.7687 - val_accuracy: 0.8203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ab0f541a30>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding early stopping callback\n",
    "#earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "#checkpoint = ModelCheckpoint('model.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "\n",
    "classifier.fit(\n",
    "        training_set,\n",
    "        steps_per_epoch=1000/32, # No of images in training set\n",
    "        epochs=10,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=100/32)\n",
    "        #callbacks=[checkpoint])\n",
    "        #callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7302ad27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 32)        9248      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 26912)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               3444864   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,454,948\n",
      "Trainable params: 3,454,948\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Saving the models\n",
    "model_json = classifier.to_json()\n",
    "with open(\"model-bw.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "classifier.save_weights('model-bw.h5')\n",
    "\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfaf28f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779549b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
